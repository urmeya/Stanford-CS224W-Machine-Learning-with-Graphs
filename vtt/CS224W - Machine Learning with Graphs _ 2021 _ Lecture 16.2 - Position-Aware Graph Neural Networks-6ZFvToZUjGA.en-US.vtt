WEBVTT
Kind: captions
Language: en-US

00:00:04.580 --> 00:00:08.460
So let me now tell you about position-aware

00:00:08.460 --> 00:00:11.705
graph neural networks that are going to solve,

00:00:11.705 --> 00:00:13.810
uh, part of the- part of the problem.

00:00:13.810 --> 00:00:18.450
So imagine there are two types of tasks on the graphs, right?

00:00:18.450 --> 00:00:19.860
There is what we are going to call

00:00:19.860 --> 00:00:23.785
structure-aware tasks and there is position-aware tasks, and, again,

00:00:23.785 --> 00:00:26.620
this is just to illustrate this concept, um,

00:00:26.620 --> 00:00:31.090
about how graph structure may affect the underlying labels.

00:00:31.090 --> 00:00:33.545
And in reality, in the real world, you know,

00:00:33.545 --> 00:00:36.530
every task is a bit of a structure-aware and a bit of a

00:00:36.530 --> 00:00:39.725
position-aware but some tasks will be more position-aware,

00:00:39.725 --> 00:00:41.430
some will be more structure-aware,

00:00:41.430 --> 00:00:45.275
and we'd like to have models that can operate in both regimes, right?

00:00:45.275 --> 00:00:49.640
When structure-aware- in structure-aware tasks, uh, for example,

00:00:49.640 --> 00:00:51.560
labeling of the nodes, uh,

00:00:51.560 --> 00:00:52.955
for this simple, uh,

00:00:52.955 --> 00:00:54.890
graph with two connected triangles,

00:00:54.890 --> 00:00:59.225
if nodes are labeled according to these labels A and B here, then, um,

00:00:59.225 --> 00:01:02.630
this is one way because the- the r- the structure

00:01:02.630 --> 00:01:06.460
of the node and the neighborhood basically defines its label.

00:01:06.460 --> 00:01:11.119
A different type of a task is what we call position-aware task,

00:01:11.119 --> 00:01:14.300
where, for example, if you think about community detection,

00:01:14.300 --> 00:01:18.755
community detection is a position-aware task right here, uh, you know,

00:01:18.755 --> 00:01:21.320
nodes on one side have one label and nodes on

00:01:21.320 --> 00:01:23.980
the other side have the other label even though their,

00:01:23.980 --> 00:01:26.980
uh, uh, uh, local structures are,

00:01:26.980 --> 00:01:29.890
uh, are comparable or iso- isomorphic, right?

00:01:29.890 --> 00:01:32.330
Like, uh, Node 1 and Node, uh, 2,

00:01:32.330 --> 00:01:35.585
um, they basically have the same neighborhood structure surrounding them.

00:01:35.585 --> 00:01:38.615
So instructure-aware tasks, they should be labeled.

00:01:38.615 --> 00:01:40.625
With the same label in position-aware,

00:01:40.625 --> 00:01:42.890
they might be labeled with different labels because they

00:01:42.890 --> 00:01:46.255
are in different parts, uh, of the network.

00:01:46.255 --> 00:01:49.580
And, uh, the point is that the GNNs,

00:01:49.580 --> 00:01:50.780
the graph neural networks,

00:01:50.780 --> 00:01:52.700
the GCN, GraphSAGE, uh,

00:01:52.700 --> 00:01:57.410
graph attention network, they work well for, uh, structure-aware tasks.

00:01:57.410 --> 00:02:02.150
Right here, basically, we can differentiate v_1 and- and v_2, um,

00:02:02.150 --> 00:02:04.910
because we are using- because they will have different,

00:02:04.910 --> 00:02:07.560
uh, computational graphs as illustrated here, right?

00:02:07.560 --> 00:02:10.400
v_1 has the following computation graph,

00:02:10.400 --> 00:02:13.910
v_2 has a different computation graph just because v_2 has

00:02:13.910 --> 00:02:17.810
three neighbors and v_1 has two neighbors even at the first hop so we are

00:02:17.810 --> 00:02:21.560
able to distinguish them and meaning we are able to assign them different labels

00:02:21.560 --> 00:02:26.095
because they'll have different embeddings because they have different computation graphs.

00:02:26.095 --> 00:02:31.320
How about position-aware tasks where now we change the labeling of the nodes,

00:02:31.320 --> 00:02:33.465
you know, let's say, according to the communities?

00:02:33.465 --> 00:02:39.230
In this case, a plain GNN is going to fail because nodes v_1 and v_2, these, uh,

00:02:39.230 --> 00:02:40.805
labeled here in the graph,

00:02:40.805 --> 00:02:42.770
have the same computation graphs

00:02:42.770 --> 00:02:45.740
because they're kind of symmetric with each other, right?

00:02:45.740 --> 00:02:47.915
So the point is that now, um,

00:02:47.915 --> 00:02:51.110
because they have the same computation graphs and, again,

00:02:51.110 --> 00:02:55.885
because we are assuming there is no discriminative node feature information given to us,

00:02:55.885 --> 00:02:57.810
the two nodes have the same, uh,

00:02:57.810 --> 00:03:01.295
local neighborhood structure, they have the same computation graph,

00:03:01.295 --> 00:03:04.504
which means they will be- they will have the same embedding,

00:03:04.504 --> 00:03:08.275
which means they will- the classifier will have to assign them the same label.

00:03:08.275 --> 00:03:10.500
Um, and in this case, we want them to,

00:03:10.500 --> 00:03:12.390
uh, label them differently.

00:03:12.390 --> 00:03:14.270
So the question is,

00:03:14.270 --> 00:03:17.030
how can we extend graph neural networks,

00:03:17.030 --> 00:03:20.360
deep learning methods that are- that would be able to, uh,

00:03:20.360 --> 00:03:23.405
solve or work well in this, uh, you know,

00:03:23.405 --> 00:03:25.490
toy example that kind of tries to

00:03:25.490 --> 00:03:29.170
illustrate this notion of position-aware prediction tasks.

00:03:29.170 --> 00:03:31.800
Um, and the key idea, uh,

00:03:31.800 --> 00:03:34.995
for this part is the notion of an anchor

00:03:34.995 --> 00:03:39.015
because the way you know your location is to- to know,

00:03:39.015 --> 00:03:41.430
um, what is your position or,

00:03:41.430 --> 00:03:44.180
uh, uh, against some reference point, right?

00:03:44.180 --> 00:03:47.660
And we are going to call these anchors to be a reference points.

00:03:47.660 --> 00:03:50.570
And if I know how far away from, uh,

00:03:50.570 --> 00:03:53.000
reference points I am and you know kind of

00:03:53.000 --> 00:03:55.970
how far away you are from different reference points,

00:03:55.970 --> 00:03:58.490
then we can, uh, distinguish our locations.

00:03:58.490 --> 00:04:02.480
It's almost like you wanna triangulate the position of the node inside

00:04:02.480 --> 00:04:06.695
the graph by- by characterizing some kind of a distance to the anchor node.

00:04:06.695 --> 00:04:08.060
So that's- that's the idea.

00:04:08.060 --> 00:04:11.410
The idea is we wanna have a reference point, um,

00:04:11.410 --> 00:04:15.740
and to quantify the location so we are going to use this notion of anchor,

00:04:15.740 --> 00:04:20.000
uh, anchor nodes to give us these, uh, locations, right?

00:04:20.000 --> 00:04:24.635
So we are going to basically pick these r- anchors at random and we are going to say,

00:04:24.635 --> 00:04:26.030
let's pick a node,

00:04:26.030 --> 00:04:28.010
let's say S_1 in this case, uh,

00:04:28.010 --> 00:04:31.925
and let's call it an anchor node and then we are going to represent

00:04:31.925 --> 00:04:37.225
the position of v_1 and v_2 by their relative distance to the, uh,

00:04:37.225 --> 00:04:40.765
anchor node and because these two- this- the distance, uh,

00:04:40.765 --> 00:04:45.510
of v_1 and v_2 in this case to the anchor node s_1 will be different, uh,

00:04:45.510 --> 00:04:48.320
this basically means that we'll allow- this will allow us to

00:04:48.320 --> 00:04:52.380
differentiate or distinguish v_1 from v_2, right?

00:04:52.380 --> 00:04:56.270
So intuitively, the anchor node serves almost like as a reference point,

00:04:56.270 --> 00:04:59.300
as a coordinate axis that tells us, um,

00:04:59.300 --> 00:05:00.950
how far away from, uh,

00:05:00.950 --> 00:05:04.770
each different nodes are and this basically allows us to, kind of,

00:05:04.770 --> 00:05:09.560
triangulate or locate the position of the node, uh, in the graph.

00:05:09.560 --> 00:05:14.075
Um, of course, we are not only- only going to use one anchor node,

00:05:14.075 --> 00:05:16.670
we are actually going to use multiple anchor nodes

00:05:16.670 --> 00:05:19.610
because if we can- if we use multiple anchor nodes,

00:05:19.610 --> 00:05:22.340
we can better characterize the position of

00:05:22.340 --> 00:05:25.330
a node in different region- regions on- of the graph.

00:05:25.330 --> 00:05:27.755
So kind of if you have multiple anchor nodes,

00:05:27.755 --> 00:05:28.970
we are able to better,

00:05:28.970 --> 00:05:31.085
um, distinguish or, uh,

00:05:31.085 --> 00:05:33.020
set, uh, our position.

00:05:33.020 --> 00:05:35.825
Of course, we don't wanna have too many becomes- beco-

00:05:35.825 --> 00:05:39.065
because then it becomes computationally hard, but, you know,

00:05:39.065 --> 00:05:41.060
having some number of them and there is actually,

00:05:41.060 --> 00:05:43.625
uh, a theory how many we wanna have, um,

00:05:43.625 --> 00:05:44.795
then, uh, we can, uh,

00:05:44.795 --> 00:05:48.335
characterize node's position in the network, uh, quite well.

00:05:48.335 --> 00:05:49.985
Here, in this case, I- you know,

00:05:49.985 --> 00:05:52.190
s_1 and s_2 are anchor nodes.

00:05:52.190 --> 00:05:55.575
Um, v_1 and v_2 are nodes of interest and I'm simply saying, you know,

00:05:55.575 --> 00:05:59.505
v_1 is one hop away from s_1 and two hops away from s_2,

00:05:59.505 --> 00:06:03.945
while v_2 is two hops away from s_1 and one hop away from, uh, s_2.

00:06:03.945 --> 00:06:07.725
And now, this kind of allows us to distinguish v_1 from, uh,

00:06:07.725 --> 00:06:12.415
v_2 because they are at different distances from these, uh, anchor nodes.

00:06:12.415 --> 00:06:14.680
Um, there is another, um,

00:06:14.680 --> 00:06:18.020
generalization that turns out to be important is

00:06:18.020 --> 00:06:21.260
that we don't wanna really only talk about anchor nodes,

00:06:21.260 --> 00:06:24.240
we wanna talk about anchor sets, right?

00:06:24.240 --> 00:06:26.870
So, uh, we are going to generalize this notion of

00:06:26.870 --> 00:06:30.710
an anchor node from a single node to a set of nodes and then we

00:06:30.710 --> 00:06:33.530
are going to define the distance between the node of interest and

00:06:33.530 --> 00:06:37.415
the anchor set as the minimum distance to any of the nodes,

00:06:37.415 --> 00:06:39.645
uh, in the anchor set, right?

00:06:39.645 --> 00:06:41.725
Um, and the idea here is that, uh,

00:06:41.725 --> 00:06:45.920
this will allow us to even triangulate the position of the node at

00:06:45.920 --> 00:06:49.940
a much more fine-grained level because anchor sets will allow us,

00:06:49.940 --> 00:06:52.130
uh, to provide more precise,

00:06:52.130 --> 00:06:54.170
uh, position information, right?

00:06:54.170 --> 00:06:59.430
Um, and it will allow us to keep the total number of anchors to be still small.

00:06:59.430 --> 00:07:01.590
So what I mean by this is that, for example,

00:07:01.590 --> 00:07:03.930
I could say, let's- let's have,

00:07:03.930 --> 00:07:05.370
uh, now anchor sets.

00:07:05.370 --> 00:07:07.590
I have, uh, anchor node s_1,

00:07:07.590 --> 00:07:09.165
I have anchor node s_2,

00:07:09.165 --> 00:07:11.310
but then also have an anchor set,

00:07:11.310 --> 00:07:16.575
I'll denote it as s_3 that includes node v_3 and, uh, s_1.

00:07:16.575 --> 00:07:19.835
And now, I'm going to characterize the distance of- uh,

00:07:19.835 --> 00:07:22.205
of a given node,

00:07:22.205 --> 00:07:25.470
uh, towards, uh, against that anchor set.

00:07:25.470 --> 00:07:27.170
Um, and in this case,

00:07:27.170 --> 00:07:30.125
for example, if I'm interested in position of v_3, uh,

00:07:30.125 --> 00:07:33.455
v_3 will have a distance of 0 to the anchor set

00:07:33.455 --> 00:07:36.690
s_3 because it is part of the anchor set while

00:07:36.690 --> 00:07:39.350
v_2 is going to have a distance of 1 because

00:07:39.350 --> 00:07:43.595
the closest node in the anchor set to v_1 is- is,

00:07:43.595 --> 00:07:45.205
uh, one hop away.

00:07:45.205 --> 00:07:48.690
Um, so, uh, what does this mean that,

00:07:48.690 --> 00:07:52.265
um, for example, if we would, as we had before,

00:07:52.265 --> 00:07:55.385
if I only use s_1 and s_2 as my anchor, uh,

00:07:55.385 --> 00:07:56.930
nodes or anchor sets,

00:07:56.930 --> 00:07:58.400
then v_3 and v- uh,

00:07:58.400 --> 00:08:01.265
uh, v_1 cannot be differentiated with each other.

00:08:01.265 --> 00:08:02.675
They have the same distances.

00:08:02.675 --> 00:08:05.360
But now if I use this anchor set of Size 2,

00:08:05.360 --> 00:08:07.270
I can actually just differentiate,

00:08:07.270 --> 00:08:09.150
uh, v_1 and v_3.

00:08:09.150 --> 00:08:13.760
And, again, there is a nice theory that says that it- it

00:08:13.760 --> 00:08:18.120
is beneficial to use anchor sets of, uh,

00:08:18.120 --> 00:08:21.150
different sizes because then the number of,

00:08:21.150 --> 00:08:23.270
uh, anchor sets, the number of coordinates,

00:08:23.270 --> 00:08:24.905
the number of reference points,

00:08:24.905 --> 00:08:26.190
uh, you need, uh,

00:08:26.190 --> 00:08:29.475
to locate a node in the graph is, uh, relatively small.

00:08:29.475 --> 00:08:31.365
It's smaller than if you would just use, uh,

00:08:31.365 --> 00:08:34.080
anchor nodes like s_1 and s_2 and add,

00:08:34.080 --> 00:08:36.250
uh, multiple, uh, anchor nodes.

00:08:36.250 --> 00:08:39.485
So what is the summary so far?

00:08:39.485 --> 00:08:41.570
Uh, we are going to de- we have just developed

00:08:41.570 --> 00:08:44.585
this positional encoding of a node in the graph,

00:08:44.585 --> 00:08:47.930
where we are going to represent a node's position by

00:08:47.930 --> 00:08:53.310
its distance to randomly selected anchor sets and each dimension in this,

00:08:53.310 --> 00:08:54.705
um, in this, uh,

00:08:54.705 --> 00:08:57.870
encoding will, uh, tell me the, uh,

00:08:57.870 --> 00:09:01.855
the- will be tied to a given anchor set and will be

00:09:01.855 --> 00:09:07.100
the minimum distance from a node of interest to any of the nodes in the anchor set.

00:09:07.100 --> 00:09:11.390
Uh, that is the- that is the idea of how we are going to,

00:09:11.390 --> 00:09:13.295
uh, uh, create this,

00:09:13.295 --> 00:09:15.460
uh, positional, uh, encoding.

00:09:15.460 --> 00:09:20.105
Now, uh, before I move on and use- how this position information is used,

00:09:20.105 --> 00:09:21.320
the way- of course,

00:09:21.320 --> 00:09:24.950
you can ask how many of these sets do you need and how big they need to be?

00:09:24.950 --> 00:09:28.100
And what we are going to do is we are going to do the following.

00:09:28.100 --> 00:09:31.205
We are going to have an e- expone- er,

00:09:31.205 --> 00:09:34.805
anchor sets of exponentially increasing size,

00:09:34.805 --> 00:09:38.820
but we are going to use exponentially fewer of them, right?

00:09:38.820 --> 00:09:40.560
So we will have a lot of, uh,

00:09:40.560 --> 00:09:42.290
anchor sets of Size 1,

00:09:42.290 --> 00:09:45.460
we'll have half that number of anchor sets of Size 2,

00:09:45.460 --> 00:09:47.415
we'll have, you know, uh,

00:09:47.415 --> 00:09:50.240
half of that number of anchor sets of Size 4,

00:09:50.240 --> 00:09:53.000
Size 8, Size 16, and so on.

00:09:53.000 --> 00:09:56.060
Um, so this- this means we'll have, you know,

00:09:56.060 --> 00:09:58.715
some relatively small number of anchor sets where

00:09:58.715 --> 00:10:02.185
each next anchor set size is going to be doubled,

00:10:02.185 --> 00:10:05.760
but the number of them will be half of what we had before.

00:10:05.760 --> 00:10:08.870
And that's usually a good way how to generate these, uh,

00:10:08.870 --> 00:10:11.930
anchor sets and the- the nodes that belong to anchor sets,

00:10:11.930 --> 00:10:13.535
we simply select them, uh,

00:10:13.535 --> 00:10:15.910
uniformly, uh, at random.

00:10:15.910 --> 00:10:19.815
And then we charac- as I said, we characterize, uh,

00:10:19.815 --> 00:10:25.720
this positional encoding of a node by simply the minimum distance from the node to the,

00:10:25.720 --> 00:10:27.220
uh, any of the nodes,

00:10:27.220 --> 00:10:30.005
uh, in the given, uh, anchor set.

00:10:30.005 --> 00:10:33.840
So now, how do we use this positional information?

00:10:33.840 --> 00:10:35.450
A simple way of using

00:10:35.450 --> 00:10:39.950
the positional information is to use it as an augmented node feature.

00:10:39.950 --> 00:10:42.125
And this works really well- well in practice.

00:10:42.125 --> 00:10:47.885
So basically, we just enrich the feature descript- descriptor of a node with this,

00:10:47.885 --> 00:10:49.970
uh, positional information, uh,

00:10:49.970 --> 00:10:52.420
characterized by the shortest path distance,

00:10:52.420 --> 00:10:53.730
uh, to the anchor sets.

00:10:53.730 --> 00:10:56.510
Uh, the issue here is that since

00:10:56.510 --> 00:11:01.445
each posi- dimension of position encoding is tied to a random anchor,

00:11:01.445 --> 00:11:03.440
dimensions of positional encoding,

00:11:03.440 --> 00:11:08.000
um, can be randomly permuted and the encoding, uh, could be,

00:11:08.000 --> 00:11:10.785
uh, basically is semantically the same meaning,

00:11:10.785 --> 00:11:13.335
um, er, er, without changing it- its meaning.

00:11:13.335 --> 00:11:15.600
So, uh, and- and what this means, uh,

00:11:15.600 --> 00:11:19.230
imagine you permute the input dimensions of a normal, uh, er, uh,

00:11:19.230 --> 00:11:22.995
er, neural network, the output will, uh, change.

00:11:22.995 --> 00:11:25.190
So what is, um,

00:11:25.190 --> 00:11:29.540
what is a more rigorous solution than just using these positional encodings as they are

00:11:29.540 --> 00:11:34.220
is to design a special set of neural network operators that can maintain this,

00:11:34.220 --> 00:11:38.150
uh, permutational invariant property of positional encoding.

00:11:38.150 --> 00:11:42.605
So basically, uh, that- the position encoding is order invariant,

00:11:42.605 --> 00:11:44.090
which you can achieve through,

00:11:44.090 --> 00:11:45.455
let's say, some kind of, uh,

00:11:45.455 --> 00:11:47.240
some aggregator or, um,

00:11:47.240 --> 00:11:50.605
uh, aggregators that are uh, order invariant.

00:11:50.605 --> 00:11:54.485
Uh, because, uh, permuting the input feature dimension

00:11:54.485 --> 00:11:58.490
will only result in the permutation of the ou- output dimension,

00:11:58.490 --> 00:12:01.520
uh, but the value of each dimension shouldn't change.

00:12:01.520 --> 00:12:04.085
And, uh, you know, there is a paper, er,

00:12:04.085 --> 00:12:07.160
that introduces position-aware graph neural networks, uh,

00:12:07.160 --> 00:12:12.440
to say how you can do this in a more rigorous way but the key here is this notion of

00:12:12.440 --> 00:12:15.230
an anchor and the notion that you can

00:12:15.230 --> 00:12:18.905
quantify the position of a node in the graph by the distance,

00:12:18.905 --> 00:12:23.630
uh, to the anchor and that allows us to now improve the expressiveness of

00:12:23.630 --> 00:12:26.510
graph neural networks because nodes won't

00:12:26.510 --> 00:12:30.185
only know what is their local neighborhood structure around them,

00:12:30.185 --> 00:12:32.515
but they will also know what is their location,

00:12:32.515 --> 00:12:34.095
uh, or position, uh,

00:12:34.095 --> 00:12:36.130
in the neural network.

