WEBVTT
Kind: captions
Language: en-US

00:00:04.190 --> 00:00:07.470
Uh, today we are going to talk about new,

00:00:07.470 --> 00:00:10.425
very interesting, and exciting problem called, uh,

00:00:10.425 --> 00:00:13.710
subgraph matching and subgraph counting or, uh,

00:00:13.710 --> 00:00:17.250
frequent subgraph counting and frequent subgraph matching.

00:00:17.250 --> 00:00:19.950
What is exciting is that we will, uh,

00:00:19.950 --> 00:00:22.575
talk about how can you do this with neural networks.

00:00:22.575 --> 00:00:25.620
So basically, how can you take a very,

00:00:25.620 --> 00:00:28.035
uh, classical, um, uh,

00:00:28.035 --> 00:00:32.775
problem, uh, kind of classical combinatorial problem and cast it as a,

00:00:32.775 --> 00:00:35.130
um, machine learning problem.

00:00:35.130 --> 00:00:37.290
Uh, and this would be the exciting part and we are

00:00:37.290 --> 00:00:39.660
going to use embeddings and graph neural networks,

00:00:39.660 --> 00:00:41.100
uh, to make this all work,

00:00:41.100 --> 00:00:44.540
and we will be able to scale it up and make it accurate, uh,

00:00:44.540 --> 00:00:48.409
and kind of swap- ste- side-stepping all the kind of complex,

00:00:48.409 --> 00:00:50.150
um, uh, discrete base,

00:00:50.150 --> 00:00:51.760
the matching and counting.

00:00:51.760 --> 00:00:55.110
So, um, here's the idea for today. All right?

00:00:55.110 --> 00:00:57.740
We are given a big graph and we would like to

00:00:57.740 --> 00:01:01.950
identify what subgraphs are common in this graph, right?

00:01:01.950 --> 00:01:05.225
Like we can think of the graph as a- as a being

00:01:05.225 --> 00:01:08.770
composed of a set of building blocks, meaning small subgraphs,

00:01:08.770 --> 00:01:12.140
and we can think of a lot of these graphs almost like being composed of

00:01:12.140 --> 00:01:15.640
these little pieces as the same way as let say, um, you know what, uh,

00:01:15.640 --> 00:01:18.125
once you build something out of Legos,

00:01:18.125 --> 00:01:21.200
that object that I know how so- that you built,

00:01:21.200 --> 00:01:24.020
it's composed of small pieces that combine it,

00:01:24.020 --> 00:01:26.270
uh, all together and create a house, right?

00:01:26.270 --> 00:01:29.240
So in some sense, what we'd like to identify is what

00:01:29.240 --> 00:01:32.555
are the most common Lego bricks that are,

00:01:32.555 --> 00:01:35.025
uh, uh, that, uh, compose the graph together.

00:01:35.025 --> 00:01:38.340
So, um, the power here will be that we are able to

00:01:38.340 --> 00:01:42.790
characterize and discriminate different networks based on these building blocks.

00:01:42.790 --> 00:01:44.360
And the task today will be,

00:01:44.360 --> 00:01:47.194
how do we identify and define,

00:01:47.194 --> 00:01:50.155
uh, these building blocks, uh, for graphs.

00:01:50.155 --> 00:01:52.264
So to give you an example,

00:01:52.264 --> 00:01:54.110
you can take a set of molecules,

00:01:54.110 --> 00:01:55.250
as I show you here,

00:01:55.250 --> 00:01:57.505
and you can represent them as graphs.

00:01:57.505 --> 00:02:03.330
and what are common substructures, uh, in these, uh,

00:02:03.330 --> 00:02:03.650
And now you can ask what are common, better,

00:02:03.650 --> 00:02:05.745
in these graphs, um, and, uh,

00:02:05.745 --> 00:02:07.700
this way I'm able to understand,

00:02:07.700 --> 00:02:11.660
let's say the structure of these molecules and what are the important substructures.

00:02:11.660 --> 00:02:12.860
In this case, for example,

00:02:12.860 --> 00:02:14.640
you could identify that this particular,

00:02:14.640 --> 00:02:16.600
um, substructure is, uh,

00:02:16.600 --> 00:02:18.579
common across all the molecules,

00:02:18.579 --> 00:02:22.090
and you know, it turns out that this is actually a very, uh, important, uh,

00:02:22.090 --> 00:02:24.250
group that, uh, would tell you whether,

00:02:24.250 --> 00:02:26.450
uh, the molecule is acidic or not, right?

00:02:26.450 --> 00:02:28.010
So in many domains,

00:02:28.010 --> 00:02:30.470
you have these recurring structural components

00:02:30.470 --> 00:02:33.150
that determine the function or the behavior,

00:02:33.150 --> 00:02:37.560
uh, of the graph similarly as this example in, uh, molecules.

00:02:37.560 --> 00:02:39.005
And of course the question is,

00:02:39.005 --> 00:02:41.285
how do we, uh, extract,

00:02:41.285 --> 00:02:45.965
identify these commonly occurring, uh, substructures?

00:02:45.965 --> 00:02:48.290
Um, we are going to, uh,

00:02:48.290 --> 00:02:50.440
approach this problem in three different, uh,

00:02:50.440 --> 00:02:52.715
kind of as a set of three steps.

00:02:52.715 --> 00:02:56.020
First, we are going to talk about subgraphs and motifs,

00:02:56.020 --> 00:02:58.540
where we are going to define what is a subgraph,

00:02:58.540 --> 00:02:59.695
what is a motif,

00:02:59.695 --> 00:03:04.355
and then we'll also talk about how do we identify, uh, significant motifs.

00:03:04.355 --> 00:03:06.460
And then after we will be done with the first step,

00:03:06.460 --> 00:03:08.635
we'll talk about how can we use

00:03:08.635 --> 00:03:12.910
graph neural networks and embeddings to represent subgraphs,

00:03:12.910 --> 00:03:16.765
and how can we then quickly identify common subgraphs, uh,

00:03:16.765 --> 00:03:20.050
using only the embedding space and no need to do,

00:03:20.050 --> 00:03:21.745
um, a very expensive, uh,

00:03:21.745 --> 00:03:24.090
discrete type, uh, matching.

00:03:24.090 --> 00:03:27.105
So let me first go and define,

00:03:27.105 --> 00:03:29.940
um, subgraphs and, uh, motifs.

00:03:29.940 --> 00:03:34.985
So, uh, here are two ways to formalize this idea of,

00:03:34.985 --> 00:03:37.730
uh, uh, building blocks of networks, all right?

00:03:37.730 --> 00:03:38.870
So we are given a network,

00:03:38.870 --> 00:03:41.870
we are given a graph with a set of nodes and a set of edges,

00:03:41.870 --> 00:03:43.320
and the first, uh,

00:03:43.320 --> 00:03:47.509
definition we will be using is called node-induced subgraph,

00:03:47.509 --> 00:03:50.525
where basically the idea is that you take a subset of nodes

00:03:50.525 --> 00:03:53.615
and all the edges that connect these nodes.

00:03:53.615 --> 00:03:56.015
So induced means it's,

00:03:56.015 --> 00:03:57.800
uh, determined by the node set.

00:03:57.800 --> 00:04:02.615
So the idea is that let's say this G prime on a- on a set of, uh,

00:04:02.615 --> 00:04:05.660
nodes V prime and a set of edges E prime is

00:04:05.660 --> 00:04:10.335
a node-induced subgraph if node set is a subset of the nodes,

00:04:10.335 --> 00:04:13.005
and then edge- edge set is simply, um,

00:04:13.005 --> 00:04:16.620
a set of all the edges that the- that the- existing the big gra- uh,

00:04:16.620 --> 00:04:21.550
in the bigger graph where both endpoints are part of my, uh, subgraph, right?

00:04:21.550 --> 00:04:24.590
So this means that G prime is a subgraph G,

00:04:24.590 --> 00:04:26.715
uh, induced by the vertex set,

00:04:26.715 --> 00:04:27.960
uh, V prime, right?

00:04:27.960 --> 00:04:29.565
So basically, induced means,

00:04:29.565 --> 00:04:31.965
it takes- it say- it ta- it means take

00:04:31.965 --> 00:04:36.330
all the edges between the- the vertices that you have determined, right?

00:04:36.330 --> 00:04:39.680
So, uh, we only get to choose the vertices, the edges.

00:04:39.680 --> 00:04:43.640
Uh, the edges are determined by the set of vertices, uh, we picked.

00:04:43.640 --> 00:04:48.060
Um, so this is what people say node-induced subgraph or generally,

00:04:48.060 --> 00:04:49.830
we just call it induced subgraph.

00:04:49.830 --> 00:04:54.320
It's basically a subgraph defined by a set of nodes where we take all the edges,

00:04:54.320 --> 00:04:55.765
uh, between that set.

00:04:55.765 --> 00:04:58.465
Um, then a second definition, uh,

00:04:58.465 --> 00:05:02.645
that is less common is to talk about edge-induced subgraphs.

00:05:02.645 --> 00:05:06.665
Here we take a subset of edges and all the corresponding nodes.

00:05:06.665 --> 00:05:11.175
So G prime is an edge-induced subgraph, um, er,

00:05:11.175 --> 00:05:14.435
simply defined by the subset of edges

00:05:14.435 --> 00:05:18.370
E prime that is a subset of the edges E in the entire network.

00:05:18.370 --> 00:05:20.275
And then now in- in this case,

00:05:20.275 --> 00:05:21.565
the V prime, uh,

00:05:21.565 --> 00:05:24.165
the set of nodes is simply defined,

00:05:24.165 --> 00:05:26.695
um, through the edges we have selected.

00:05:26.695 --> 00:05:29.445
Um, so in-in- in,

00:05:29.445 --> 00:05:31.770
um, the terminology we'll be using, usually,

00:05:31.770 --> 00:05:32.850
we say this that this is

00:05:32.850 --> 00:05:36.720
a non-induced subgraph or just a subgraph because it's determined,

00:05:36.720 --> 00:05:40.115
uh, by the set of edges rather than by the set of nodes.

00:05:40.115 --> 00:05:41.530
When we say induced subgraph,

00:05:41.530 --> 00:05:44.180
we would mean select the set of nodes and,

00:05:44.180 --> 00:05:45.690
um, determine the edges,

00:05:45.690 --> 00:05:46.970
and when we say non-induced,

00:05:46.970 --> 00:05:49.685
it would mean just select the node- the edges,

00:05:49.685 --> 00:05:53.300
and then the nodes get automatically, uh, determined.

00:05:53.300 --> 00:05:57.965
The- the two ways of formalizing network buil- building blocks,

00:05:57.965 --> 00:05:59.855
um, it will really depend,

00:05:59.855 --> 00:06:01.880
uh, on the domain we are interested in.

00:06:01.880 --> 00:06:07.180
Most often people like to work with induced subgraphs because otherwise if you do edge,

00:06:07.180 --> 00:06:09.360
uh, induced subgraphs, the, er,

00:06:09.360 --> 00:06:10.635
the number of, uh,

00:06:10.635 --> 00:06:12.870
possibilities, uh, explodes.

00:06:12.870 --> 00:06:15.425
So especially in natural science domains like

00:06:15.425 --> 00:06:18.725
chemistry and so on where we worry about functional groups,

00:06:18.725 --> 00:06:20.890
we are going to use node-induced subgraphs.

00:06:20.890 --> 00:06:22.670
Uh, in other domains, for example,

00:06:22.670 --> 00:06:25.770
knowledge graphs, it is actually often edge-induced subgraphs.

00:06:25.770 --> 00:06:29.270
For example, if you think about focusing edges that represent,

00:06:29.270 --> 00:06:32.980
uh, local logical, uh, relations.

00:06:32.980 --> 00:06:37.955
So now that we have defined these two no- notions of a subgraph,

00:06:37.955 --> 00:06:39.260
then, um, you know,

00:06:39.260 --> 00:06:42.500
the preceding definitions of subgraphs, uh, uh,

00:06:42.500 --> 00:06:47.000
basically say that V prime is a subset of V and E prime is a subset of E,

00:06:47.000 --> 00:06:50.585
which mean- basically means that nodes and edges are taken from the original graph,

00:06:50.585 --> 00:06:52.780
uh, G. Now, um,

00:06:52.780 --> 00:06:54.660
you could also say, okay, what if,

00:06:54.660 --> 00:06:58.880
er, V prime and E prime comes from totally different, uh, graphs?

00:06:58.880 --> 00:07:01.535
For example, you could- can you somehow define that,

00:07:01.535 --> 00:07:02.960
you know, you have two different graphs,

00:07:02.960 --> 00:07:08.475
G_1 and G_2, could you somehow say that G_1 is contained in G_2?

00:07:08.475 --> 00:07:10.470
Right? G_1 is this triangle of three nodes,

00:07:10.470 --> 00:07:11.985
and we can see that in G_2,

00:07:11.985 --> 00:07:15.615
this triangle is contained by the subgraph X,

00:07:15.615 --> 00:07:17.340
uh, Y, uh, and Z.

00:07:17.340 --> 00:07:23.180
So how do we say that one graph G_1 is contained in another,

00:07:23.180 --> 00:07:25.775
let's say bigger graph, uh, G_2.

00:07:25.775 --> 00:07:29.765
The way we do this is that we need to define the- the, uh,

00:07:29.765 --> 00:07:33.530
problem or the task of graph isomorphism,

00:07:33.530 --> 00:07:36.155
where the graph isomorphism problem,

00:07:36.155 --> 00:07:38.165
uh, i- is the following problem,

00:07:38.165 --> 00:07:40.550
you wanna check basically say, yes,

00:07:40.550 --> 00:07:43.410
no, whether two graphs are identical.

00:07:43.410 --> 00:07:47.805
So the idea is on having graph G_1 on some nodes and edges,

00:07:47.805 --> 00:07:49.800
and I have graph G_2 and again,

00:07:49.800 --> 00:07:51.465
some nodes, uh, and edges.

00:07:51.465 --> 00:07:54.165
And I say that G_1 and G_2 are isomorphic.

00:07:54.165 --> 00:07:56.790
If there exists a bijection, basically,

00:07:56.790 --> 00:07:58.370
it mea- means there exists

00:07:58.370 --> 00:08:02.570
a one-to-one mapping between the nodes of one graph to the nodes,

00:08:02.570 --> 00:08:04.930
uh, of the other graph such that,

00:08:04.930 --> 00:08:07.230
uh, all the edges, uh, are preserved.

00:08:07.230 --> 00:08:09.225
Meaning if u and v are connected in,

00:08:09.225 --> 00:08:12.180
um, uh, in the graph 1,

00:08:12.180 --> 00:08:15.135
then the mapping of node, uh, uh,

00:08:15.135 --> 00:08:17.610
u and the mapping of node v,

00:08:17.610 --> 00:08:20.025
uh, is also connected, uh, in graph 2.

00:08:20.025 --> 00:08:22.200
So this a and b should actually be, uh,

00:08:22.200 --> 00:08:24.735
u and v, so we need- we'll fix that, right?

00:08:24.735 --> 00:08:28.410
So this mapping F is called graph isomorphism.

00:08:28.410 --> 00:08:30.005
So to give you an example,

00:08:30.005 --> 00:08:32.240
if I have two graphs here, you know,

00:08:32.240 --> 00:08:33.590
one- one looks like this,

00:08:33.590 --> 00:08:34.820
the other one looks like that,

00:08:34.820 --> 00:08:38.570
they are isomorphic because if I, uh, map, uh,

00:08:38.570 --> 00:08:41.180
these nodes, uh, one to the, uh,

00:08:41.180 --> 00:08:43.375
one to the other, as I show it here,

00:08:43.375 --> 00:08:45.200
then basically, uh, the edges,

00:08:45.200 --> 00:08:47.495
for example, these two nodes are connected here,

00:08:47.495 --> 00:08:48.995
they're also connected there,

00:08:48.995 --> 00:08:52.310
this- there is this connection which is here, and so on.

00:08:52.310 --> 00:08:54.650
So clearly, these two graphs are isomorphic.

00:08:54.650 --> 00:08:57.180
I can map nodes from one to the other,

00:08:57.180 --> 00:08:59.354
and I'm able to preserve,

00:08:59.354 --> 00:09:00.555
uh, all the edges.

00:09:00.555 --> 00:09:02.390
In this- in a similar sense,

00:09:02.390 --> 00:09:04.325
these two graphs are non-isomorphic

00:09:04.325 --> 00:09:07.655
because there is no way for me to map these four nodes, uh,

00:09:07.655 --> 00:09:10.610
of the left graph to the nodes of the right graph,

00:09:10.610 --> 00:09:12.950
such that if two nodes are connected on the left,

00:09:12.950 --> 00:09:15.735
I'd know they are also connected on the right.

00:09:15.735 --> 00:09:18.220
Um, so this is the problem of

00:09:18.220 --> 00:09:21.625
Graph Isomorphism is checking whether two graphs are identical.

00:09:21.625 --> 00:09:24.310
And- and the issue here is that we

00:09:24.310 --> 00:09:27.425
don't know how map- how nodes map to each other, right?

00:09:27.425 --> 00:09:34.030
It goes back to this idea that ordering or- i- i- no- ideas of the nodes are arbitrary.

00:09:34.030 --> 00:09:36.730
So really there is no special order to them.

00:09:36.730 --> 00:09:38.740
So we really need to check in some sense,

00:09:38.740 --> 00:09:44.125
all possible orderings to determine if one graph is the same than the other graph.

00:09:44.125 --> 00:09:45.880
Um, and if you ask, "Okay,

00:09:45.880 --> 00:09:49.795
so how hard is this graph isomorphism step um, problem?

00:09:49.795 --> 00:09:55.255
It is actually not known whether graph isomorphism is NP-hard.

00:09:55.255 --> 00:10:00.700
But we don't know any polynomial algorithm for solving graph isomorphism.

00:10:00.700 --> 00:10:01.960
So it seems it's this kind of

00:10:01.960 --> 00:10:07.180
super interesting problem where we cannot prove that it's NP-hard,

00:10:07.180 --> 00:10:09.940
at same time, we don't know uh,

00:10:09.940 --> 00:10:12.085
any algorithm or nobody was able to

00:10:12.085 --> 00:10:15.295
determine the algorithm that would solve this in polynomial time.

00:10:15.295 --> 00:10:17.815
So it's somewhere in between. Nobody knows.

00:10:17.815 --> 00:10:20.050
Still a big open question.

00:10:20.050 --> 00:10:23.350
So this is now the notion of graph isomorphism.

00:10:23.350 --> 00:10:27.310
So now we can define the notion of subgraph isomorphism.

00:10:27.310 --> 00:10:29.200
Where do we say that uh,

00:10:29.200 --> 00:10:35.245
G- G2 is subgraph isomorphic to G1 if for some subgraph of G2,

00:10:35.245 --> 00:10:38.230
the subgraph is isomorphic to G1.

00:10:38.230 --> 00:10:45.745
So um, what they commonly say is also that simply that G1 is a subgraph of G2, right?

00:10:45.745 --> 00:10:50.165
And we can use either node or edge induced subgraph definition in this case.

00:10:50.165 --> 00:10:53.275
And this problem is known to be NP-hard.

00:10:53.275 --> 00:10:54.730
To give you an example, right,

00:10:54.730 --> 00:10:57.085
this is G1, this is the graph G2.

00:10:57.085 --> 00:11:01.405
I say G1 is subgraph isomorphic to G2,

00:11:01.405 --> 00:11:04.360
or G1 is a subgraph of G2.

00:11:04.360 --> 00:11:07.030
Because if I use this particular node mapping, right?

00:11:07.030 --> 00:11:09.850
A maps to X, B maps to Y,

00:11:09.850 --> 00:11:11.455
and C maps to Z,

00:11:11.455 --> 00:11:17.135
then these connections between the three nodes in G1 are preserved in G2 as well.

00:11:17.135 --> 00:11:20.245
Notice that we don't care about additional connections.

00:11:20.245 --> 00:11:25.295
So this doesn't matter because this node- this structure is not part of G1.

00:11:25.295 --> 00:11:28.060
And the other thing that is also important to note is

00:11:28.060 --> 00:11:30.970
that this mapping does not need to be unique.

00:11:30.970 --> 00:11:35.500
It is just enough to find one mapping where I map nodes of one er,

00:11:35.500 --> 00:11:39.835
sub er, graph to the nodes of the other graph in a unique way,

00:11:39.835 --> 00:11:41.200
in a one-to-one mapping.

00:11:41.200 --> 00:11:44.195
So it's- two nodes cannot map to the same nodes.

00:11:44.195 --> 00:11:45.955
Right, so in this case,

00:11:45.955 --> 00:11:51.415
we have now been able to mathematically define and determine that

00:11:51.415 --> 00:11:57.250
G1 is a subgraph of G2 because there exists this bijective mapping,

00:11:57.250 --> 00:12:00.760
so one-to-one mapping, so that uh, every- any er,

00:12:00.760 --> 00:12:04.885
nodes from G1 map to G2 and if two nodes in G1 are connected,

00:12:04.885 --> 00:12:08.935
then their maps, uh their transformations are

00:12:08.935 --> 00:12:12.910
also connected in G2 and the other way around, right?

00:12:12.910 --> 00:12:16.030
So that's the- that's the important uh, part here.

00:12:16.030 --> 00:12:19.735
So now um, we have th- what have we learned so far?

00:12:19.735 --> 00:12:21.670
We defined the notion of a subgraph.

00:12:21.670 --> 00:12:25.615
We defined the notion of a graph isomorphism problem,

00:12:25.615 --> 00:12:29.290
and then we also defined the notion of a subgraph isomorphism problem, right?

00:12:29.290 --> 00:12:33.550
Basically saying is wha- is a small graph contained in the bigger graph?

00:12:33.550 --> 00:12:35.380
Now, of course, um,

00:12:35.380 --> 00:12:37.000
when we talked about subgraphs,

00:12:37.000 --> 00:12:41.550
usually we are interested in all subgraphs up to a given size.

00:12:41.550 --> 00:12:49.855
Size, meaning the number of nodes if we talk about different subgraphs of given size.

00:12:49.855 --> 00:12:53.350
So to show, actually there is a lot of

00:12:53.350 --> 00:12:58.090
different subgraphs of a given size and this number increases very, very fast.

00:12:58.090 --> 00:13:01.255
So for example, if here I show an example of

00:13:01.255 --> 00:13:06.220
all non isomorphic connected undirected graphs of size 4, right?

00:13:06.220 --> 00:13:09.640
These are all possible graphs on four nodes, um,

00:13:09.640 --> 00:13:11.605
where the number of nodes is fixed,

00:13:11.605 --> 00:13:13.405
number of edges can vary,

00:13:13.405 --> 00:13:16.300
and the other constraint is that these graphs are connected.

00:13:16.300 --> 00:13:21.730
So there is four different graphs on four nodes undirected.

00:13:21.730 --> 00:13:24.340
Now, for example, if you say what are

00:13:24.340 --> 00:13:28.810
non-isomorphic connected directed graphs of size 3,

00:13:28.810 --> 00:13:31.360
if you look at that, there's already 13 of them, right?

00:13:31.360 --> 00:13:32.530
It's only three nodes.

00:13:32.530 --> 00:13:34.225
But because edges are directed,

00:13:34.225 --> 00:13:36.604
I can have edges in different directions,

00:13:36.604 --> 00:13:40.580
and this gives me 13 different uh, graphs.

00:13:40.580 --> 00:13:43.225
So what does- wh- why is this important?

00:13:43.225 --> 00:13:45.775
Because if I have a directed graph and I say,

00:13:45.775 --> 00:13:49.150
what are the building blocks of size 3,

00:13:49.150 --> 00:13:52.285
then I would need to determine the frequency,

00:13:52.285 --> 00:13:56.830
the number of times this particular subgraph number 1 is included in the big graph.

00:13:56.830 --> 00:14:00.055
And then I need to determine how often is this guy um,

00:14:00.055 --> 00:14:01.570
included and so on.

00:14:01.570 --> 00:14:05.840
So the point is that the number of these building blocks,

00:14:05.840 --> 00:14:09.040
different subgraphs, increases super exponentially.

00:14:09.040 --> 00:14:15.200
So in general, people usually only counted these building blocks up to size 4, 5.

00:14:15.200 --> 00:14:16.825
Because even at the level of 5,

00:14:16.825 --> 00:14:19.840
there is thousands of them and it's kind of a lot to

00:14:19.840 --> 00:14:23.335
keep track of and it becomes a very hard computational problem.

00:14:23.335 --> 00:14:28.355
So now that we have defined the notion of subgraphs inclusion,

00:14:28.355 --> 00:14:29.560
and I showed you that there are

00:14:29.560 --> 00:14:35.590
many different possible subgraphs that are non-isomorphic with a given number of nodes.

00:14:35.590 --> 00:14:39.370
Then, now we define the next concept that um,

00:14:39.370 --> 00:14:41.275
will be important for today's discussion,

00:14:41.275 --> 00:14:44.225
and this is the concept of a network motif.

00:14:44.225 --> 00:14:47.540
A network motif is defined as a recurrent,

00:14:47.540 --> 00:14:51.735
significant pattern of interconnections in a graph.

00:14:51.735 --> 00:14:57.400
So now let's unpack this and determine like this, make it precise.

00:14:57.400 --> 00:14:58.810
What do we mean by this?

00:14:58.810 --> 00:15:03.175
First is um, we define a network motif as a pattern,

00:15:03.175 --> 00:15:06.440
which means a small node induced subgraph.

00:15:06.440 --> 00:15:09.220
Then we need to say what do we mean recurring, right?

00:15:09.220 --> 00:15:12.700
Recurring means it has to appear multiple times, right?

00:15:12.700 --> 00:15:14.200
It has to have high frequency.

00:15:14.200 --> 00:15:18.805
It has to be contained many times in the underlying graph of interest.

00:15:18.805 --> 00:15:22.550
And then there is another interesting part,

00:15:22.550 --> 00:15:24.565
where we say significant,

00:15:24.565 --> 00:15:30.205
and significant means that it's more frequent than what we would expect.

00:15:30.205 --> 00:15:33.670
And of course, if you say more frequent than what we would expect,

00:15:33.670 --> 00:15:36.040
then you need to have some way to say,

00:15:36.040 --> 00:15:37.930
okay, but what would I expect?

00:15:37.930 --> 00:15:40.270
And this means you need to have a null model,

00:15:40.270 --> 00:15:42.640
you need to have a random graph null model.

00:15:42.640 --> 00:15:45.175
So you say, aha, what I would expect in the model,

00:15:45.175 --> 00:15:48.580
what I see in the reality, is there a big discrepancy?

00:15:48.580 --> 00:15:49.959
If there is a big discrepancy,

00:15:49.959 --> 00:15:51.940
this- then this subgraph pattern,

00:15:51.940 --> 00:15:57.625
this motif must be an important thing so let's surface it out to the scientists.

00:15:57.625 --> 00:15:59.035
To give you an idea.

00:15:59.035 --> 00:16:03.925
Imagine I'm interested in this particular motif on three nodes in a directed graph,

00:16:03.925 --> 00:16:06.730
then when I talk about motifs,

00:16:06.730 --> 00:16:08.560
these motifs need to be induced.

00:16:08.560 --> 00:16:11.620
So for example, this is not an instance of the motif

00:16:11.620 --> 00:16:14.690
of interest because actually this is a triangle of three nodes.

00:16:14.690 --> 00:16:15.970
It's not so bad, so

00:16:15.970 --> 00:16:17.950
there's no edge in my motif here,

00:16:17.950 --> 00:16:19.690
but there is there, for example.

00:16:19.690 --> 00:16:24.190
So really the instance is here because this- this particular subgraph of interest,

00:16:24.190 --> 00:16:27.475
this motif appears here and there is one-to-one mapping.

00:16:27.475 --> 00:16:31.705
So I say, aha, I found this- the incidence of this thing here.

00:16:31.705 --> 00:16:33.070
Of course, you know,

00:16:33.070 --> 00:16:38.370
there are many other places where this same motif occurs.

00:16:38.370 --> 00:16:41.000
So um, the question is,

00:16:41.000 --> 00:16:43.235
why do we need this notion of motifs?

00:16:43.235 --> 00:16:48.425
And motifs help us understand how uh, graphs work, how networks work.

00:16:48.425 --> 00:16:52.160
They help uh, make us- they help us to make predictions based

00:16:52.160 --> 00:16:56.195
on the presence or lack of presence uh, of a motif in a data set.

00:16:56.195 --> 00:16:59.585
So for example, uh, feed-forward uh, loops,

00:16:59.585 --> 00:17:02.090
this is defined as a feed-forward loop motif,

00:17:02.090 --> 00:17:04.715
were found to be important, um,

00:17:04.715 --> 00:17:09.875
for, uh, networks of neurons for- so basically for brain networks because they,

00:17:09.875 --> 00:17:13.080
uh, neutralize what is called biological noise, uh.

00:17:13.080 --> 00:17:18.395
Parallel loops are important in- in food webs because it says that,

00:17:18.395 --> 00:17:21.350
um, eh, are given predators preying, uh, uh,

00:17:21.350 --> 00:17:25.865
on two different uh, species that have a common food source,

00:17:25.865 --> 00:17:27.230
and you know in, for example,

00:17:27.230 --> 00:17:28.340
in gene control networks,

00:17:28.340 --> 00:17:32.390
you have a lot of this type of a single- what is called single input modules

00:17:32.390 --> 00:17:37.655
where um, this gene regulates uh, a lot of uh, other uh, genes.

00:17:37.655 --> 00:17:40.970
So these are some examples of uh, significance of

00:17:40.970 --> 00:17:45.470
motifs uh, for the function of a given underlying network.

00:17:45.470 --> 00:17:50.180
So now, uh, let's go and define the two things we discussed.

00:17:50.180 --> 00:17:52.175
First is, we need to define frequency,

00:17:52.175 --> 00:17:54.635
second, we need to define significance.

00:17:54.635 --> 00:17:57.050
So let's define frequency first, right?

00:17:57.050 --> 00:18:03.230
Let's say G_Q is a small uh, sub-graph of interest and Gt be the big target graph.

00:18:03.230 --> 00:18:07.370
Uh, and then we say that we will define a um, graph, uh,

00:18:07.370 --> 00:18:11.360
level, subgraph frequency uh, by the following definition.

00:18:11.360 --> 00:18:16.190
We'll say that frequency G- of this graph G_Q in the bigger graph,

00:18:16.190 --> 00:18:21.065
G_T is the number of unique subsets of nodes, um, in, uh,

00:18:21.065 --> 00:18:24.635
the big graph, for each the sub-graph, uh, um,

00:18:24.635 --> 00:18:28.550
of the big graph induced by- by its nodes is- is,

00:18:28.550 --> 00:18:29.885
uh, isomorphic to this,

00:18:29.885 --> 00:18:32.300
let's call it G_Q, so the query graph.

00:18:32.300 --> 00:18:35.030
So to give you- to give you an example, right,

00:18:35.030 --> 00:18:36.110
this is kind of a mouthful,

00:18:36.110 --> 00:18:38.450
but the intuition is actually quite simple.

00:18:38.450 --> 00:18:40.100
Here I have the query graph,

00:18:40.100 --> 00:18:41.735
here I have the target graph.

00:18:41.735 --> 00:18:45.005
This query graph appears twice in the target graph, you know,

00:18:45.005 --> 00:18:47.045
there two triangles, one is here,

00:18:47.045 --> 00:18:48.260
the other one is here,

00:18:48.260 --> 00:18:50.120
so the frequency would be 2.

00:18:50.120 --> 00:18:52.729
Um, here's a different example,

00:18:52.729 --> 00:18:55.790
imagine I have this star sub-graph um,

00:18:55.790 --> 00:18:56.885
and I want to ask it,

00:18:56.885 --> 00:19:00.365
how often does it appear in this graph, um, of uh,

00:19:00.365 --> 00:19:04.550
interest? Actually here um, perhaps counter-intuitively,

00:19:04.550 --> 00:19:07.400
the frequency will- will be super large because, you know,

00:19:07.400 --> 00:19:09.785
the center node will map to the center node,

00:19:09.785 --> 00:19:11.600
but then the number of the satellite,

00:19:11.600 --> 00:19:13.550
these uh, leaf nodes um,

00:19:13.550 --> 00:19:17.195
is huge because I can select any 6 out of 100,

00:19:17.195 --> 00:19:18.815
and any 6 I select,

00:19:18.815 --> 00:19:20.405
it's a different mapping.

00:19:20.405 --> 00:19:23.660
So I basically count how many different ways am I able to

00:19:23.660 --> 00:19:26.900
take this graph and map it to the target graphs?

00:19:26.900 --> 00:19:28.010
So in this case,

00:19:28.010 --> 00:19:31.430
the number of different mappings would be

00:19:31.430 --> 00:19:36.275
100 choose 6 because out of the 100 nodes here,

00:19:36.275 --> 00:19:39.485
uh, I want to choose different subsets of 6

00:19:39.485 --> 00:19:42.785
because the s- the star graph uh, has uh, 6 nodes.

00:19:42.785 --> 00:19:47.330
So here the frequency of this um, would be um, would be huge.

00:19:47.330 --> 00:19:54.140
So um, this is uh, the graph-level sub-graph frequency uh, definition.

00:19:54.140 --> 00:19:56.120
Uh, there is uh, also

00:19:56.120 --> 00:19:58.730
a more precise uh, frequency definition ca-

00:19:58.730 --> 00:20:02.435
called node level uh, sub-graph frequency definition,

00:20:02.435 --> 00:20:06.230
and here the idea is that uh the query comes

00:20:06.230 --> 00:20:10.685
with a- uh, comes with the graph as well as with an anchor.

00:20:10.685 --> 00:20:12.620
And then we do the mapping,

00:20:12.620 --> 00:20:17.390
we say to how many different nodes can this anchor be mapped?

00:20:17.390 --> 00:20:22.790
Uh, so that this uh, sub-graph Q is contained uh, in the target graph, right?

00:20:22.790 --> 00:20:24.035
So here we are saying,

00:20:24.035 --> 00:20:32.390
I want to be able to map uh, the edges of the- of the graph uh, Q to the graph uh, T,

00:20:32.390 --> 00:20:39.140
and I want to count to how many different nodes can this anchor uh, node uh, be mapped?

00:20:39.140 --> 00:20:41.030
So in our case, for example,

00:20:41.030 --> 00:20:43.445
if I have this star graph from the previous case,

00:20:43.445 --> 00:20:48.875
and I select a center as- as a uh, as an anchor,

00:20:48.875 --> 00:20:54.185
then the frequency of this um, graph in my target graph would be uh, 1.

00:20:54.185 --> 00:20:58.265
So there is only one way to map this anchor uh, to my target graph.

00:20:58.265 --> 00:21:02.100
For example, if I were to select the anchor as one of the satellites,

00:21:02.100 --> 00:21:08.185
then the frequency of the sub-graph would be 100 because there is exactly 100 ways to map

00:21:08.185 --> 00:21:12.070
the anchor to one of these 100 nodes such that the

00:21:12.070 --> 00:21:16.795
entire sub-graph maps uh, to the uh, to the target graph.

00:21:16.795 --> 00:21:21.130
So this is um, the node level sub-graph definition,

00:21:21.130 --> 00:21:24.430
where we have this kind of anchor and we are asking how often can we

00:21:24.430 --> 00:21:28.650
map the anchor together with the corresponding uh, sub-graph?

00:21:28.650 --> 00:21:34.985
Okay. So now uh, that we have defined the notion of a sub-graph frequency, uh,

00:21:34.985 --> 00:21:36.740
the graph level and the node level,

00:21:36.740 --> 00:21:38.360
the last thing to say is, you know,

00:21:38.360 --> 00:21:40.640
is it a problem if the graph is disconnected?

00:21:40.640 --> 00:21:43.745
If I have multiple small connected graphs- disconnected graphs.

00:21:43.745 --> 00:21:45.440
Solution is very simple,

00:21:45.440 --> 00:21:47.330
I can s- simply treat

00:21:47.330 --> 00:21:50.780
all these small um, separate sub-graphs

00:21:50.780 --> 00:21:54.470
as one giant graph with multiple connected components,

00:21:54.470 --> 00:21:57.110
so that is uh, no problem uh, at all,

00:21:57.110 --> 00:21:58.850
just to kind of address this point.

00:21:58.850 --> 00:22:01.715
So now that we have defined frequency,

00:22:01.715 --> 00:22:03.920
we need to define the significance,

00:22:03.920 --> 00:22:08.210
and we will define motif significance um, in a way that we compare

00:22:08.210 --> 00:22:12.709
it- we p- compare the number of occurrences with some null-model,

00:22:12.709 --> 00:22:16.130
with some kind of point of comparison and the idea is that if

00:22:16.130 --> 00:22:20.615
a given sub-graph occurs um, in a real graph much more often,

00:22:20.615 --> 00:22:22.580
than uh, than in a random network,

00:22:22.580 --> 00:22:26.240
then this- then it has a signi- functional significance.

00:22:26.240 --> 00:22:31.775
So let me now define uh, quickly how do we generate random graphs?

00:22:31.775 --> 00:22:35.150
And the first way to define a random graph is

00:22:35.150 --> 00:22:38.255
uh, the model called Erdos-Renyi random graph model.

00:22:38.255 --> 00:22:43.385
And this random graph model has- is a stochastic graph model that has two parameters.

00:22:43.385 --> 00:22:45.605
It has um, n and a p,

00:22:45.605 --> 00:22:47.015
n is the number of nodes,

00:22:47.015 --> 00:22:49.010
and p is a probability of an edge.

00:22:49.010 --> 00:22:51.515
So how do you generate a graph from this model?

00:22:51.515 --> 00:22:55.910
You simply create n isolated nodes and then for each pair of nodes,

00:22:55.910 --> 00:22:59.705
you flip a biased coin with a bias p, and if the-

00:22:59.705 --> 00:23:03.905
the- the- tai- the coin flip says create an edge,

00:23:03.905 --> 00:23:05.435
then you would create an edge,

00:23:05.435 --> 00:23:09.140
and uh, right, the generated graph is a result of a random process,

00:23:09.140 --> 00:23:12.380
so the more t- the- you can generate multiple graphs and they'll be

00:23:12.380 --> 00:23:15.890
different because the coin flips uh, will come up uh, differently.

00:23:15.890 --> 00:23:17.630
Even if you set the same parameters,

00:23:17.630 --> 00:23:19.100
here, you know, I have five nodes,

00:23:19.100 --> 00:23:23.330
so n is 5 and probability of an edge is 0.6 and, you know,

00:23:23.330 --> 00:23:25.760
this would be le- let's say three instances of

00:23:25.760 --> 00:23:30.245
a random graph generated from this G n, p model.

00:23:30.245 --> 00:23:33.770
So um, now the next question is,

00:23:33.770 --> 00:23:36.125
can we have a more precise uh, model?

00:23:36.125 --> 00:23:38.630
Like- because in this model, all I get to

00:23:38.630 --> 00:23:42.530
specify is the number of nodes, and the probability of an edge.

00:23:42.530 --> 00:23:47.330
So actually there is a more precise model uh, that is called configuration

00:23:47.330 --> 00:23:52.250
model and the goal here is to generate a random graph with a given degree sequence.

00:23:52.250 --> 00:23:56.390
So what does this mean is, if I have my real graph Gt,

00:23:56.390 --> 00:23:58.880
I want to generate a random version of it.

00:23:58.880 --> 00:24:02.420
One way to have a random version of it would simply be to say, you know,

00:24:02.420 --> 00:24:04.220
my Gt has n nodes,

00:24:04.220 --> 00:24:07.970
so let me generate an Erdos-Renyi random graph with n nodes.

00:24:07.970 --> 00:24:12.230
And I will set the value of parameter p such that in expectation

00:24:12.230 --> 00:24:17.315
this random Erdos-Renyi graph will have the same number of edges as my uh, G_t.

00:24:17.315 --> 00:24:21.440
So I match in terms of number of nodes and the number of edges.

00:24:21.440 --> 00:24:24.350
Um, in the configuration model,

00:24:24.350 --> 00:24:26.945
we are going to match both the number of nodes,

00:24:26.945 --> 00:24:30.575
number of edges, but also the degrees of the nodes.

00:24:30.575 --> 00:24:33.245
So basically, we will say I wanna generate

00:24:33.245 --> 00:24:35.960
a random graph that has a given degree sequence,

00:24:35.960 --> 00:24:38.720
meaning I have nodes 1- n,

00:24:38.720 --> 00:24:40.970
and each node has a given degree.

00:24:40.970 --> 00:24:45.290
But I don't specify how the nodes connect to each other.

00:24:45.290 --> 00:24:46.955
Um, the way I do this,

00:24:46.955 --> 00:24:48.965
it's actually quite simple and elegant.

00:24:48.965 --> 00:24:53.930
I create n nodes and for every node I create, uh, uh, k_i,

00:24:53.930 --> 00:24:56.960
uh, spokes, right? So for example,

00:24:56.960 --> 00:24:58.475
node B has degree 4,

00:24:58.475 --> 00:25:00.080
so it has four spokes.

00:25:00.080 --> 00:25:01.475
Node C has, uh,

00:25:01.475 --> 00:25:03.829
degree 2, so it has two spokes.

00:25:03.829 --> 00:25:08.570
What I can do now is I represent every spoke,

00:25:08.570 --> 00:25:10.280
uh, as a node, right?

00:25:10.280 --> 00:25:15.980
I take these spokes and I create spokes as nodes and- and the spokes from,

00:25:15.980 --> 00:25:17.930
er, every, er, every, er,

00:25:17.930 --> 00:25:21.335
supernode are- are kind of belong to a given box.

00:25:21.335 --> 00:25:23.885
What I do now is I go and, uh,

00:25:23.885 --> 00:25:26.870
I randomly pair up, uh, the spokes, right?

00:25:26.870 --> 00:25:29.240
I basically- I randomly pair up these nodes.

00:25:29.240 --> 00:25:31.910
And then I determine, um,

00:25:31.910 --> 00:25:35.150
an edge between a pair of nodes if at least one spoke

00:25:35.150 --> 00:25:38.450
from one partition links to the spoken the other partition.

00:25:38.450 --> 00:25:43.340
So for example here, A and B are connected here because there is a node in,

00:25:43.340 --> 00:25:45.755
uh, A that links to a node B.

00:25:45.755 --> 00:25:50.900
Uh, of course, what is the issue here is sometimes it will happen that I will have,

00:25:50.900 --> 00:25:53.420
uh, multiple spokes linked to each other

00:25:53.420 --> 00:25:55.910
and that will only result in a single- single edge.

00:25:55.910 --> 00:25:57.500
So I'm going to ignore that.

00:25:57.500 --> 00:25:59.570
And of course it can also happen that for example,

00:25:59.570 --> 00:26:01.340
these two nodes would link to each other.

00:26:01.340 --> 00:26:03.770
So this would correspond to a self-loop.

00:26:03.770 --> 00:26:06.755
And I'm also going to, uh, ignore this.

00:26:06.755 --> 00:26:10.325
And kind of the reason why I can ignore all this is because, uh,

00:26:10.325 --> 00:26:15.710
in practice, the probability of there being multiple edges between, um, er,

00:26:15.710 --> 00:26:19.070
spokes coming from the same node or, um,

00:26:19.070 --> 00:26:24.485
being a se- generating a self-loop is so- is so small that I can, uh,

00:26:24.485 --> 00:26:26.795
ignore it for all practical, er,

00:26:26.795 --> 00:26:29.120
purposes and also kind of mathematically,

00:26:29.120 --> 00:26:31.790
uh, you can ignore it because it is, uh, so rare.

00:26:31.790 --> 00:26:34.160
So basically this means that now I have

00:26:34.160 --> 00:26:37.430
a very useful null-model of networks because I can compare

00:26:37.430 --> 00:26:38.990
the real network with

00:26:38.990 --> 00:26:43.370
a random version of the network that has the same degree sequence, right?

00:26:43.370 --> 00:26:48.140
Node have the- nodes have the same degrees as in the, uh, G-real.

00:26:48.140 --> 00:26:53.432
And now this gives me another different null-model where basically I create spokes, I

00:26:53.432 --> 00:26:59.480
then create a G n, p by randomly connecting the spokes and then join these spoky nodes.

00:26:59.480 --> 00:27:01.730
These mini-nodes it to get back,

00:27:01.730 --> 00:27:04.205
er, a resulting, uh, graph.

00:27:04.205 --> 00:27:07.235
So now that we have defined, uh,

00:27:07.235 --> 00:27:11.045
two random models, the configuration model and the Erdos-Renyi model,

00:27:11.045 --> 00:27:14.600
uh, generally, we would prefer to use the configuration model.

00:27:14.600 --> 00:27:16.865
Now, we need to def- determine,

00:27:16.865 --> 00:27:19.430
uh, and define what is motif significance.

00:27:19.430 --> 00:27:23.600
And the- the intuition is that motif is already represented in a network,

00:27:23.600 --> 00:27:26.780
uh, when we compare it to this random null-graph.

00:27:26.780 --> 00:27:28.520
So the idea is the following.

00:27:28.520 --> 00:27:31.430
I'm going to pick a sub-graph of interest and

00:27:31.430 --> 00:27:34.835
I'm going to count its frequency in the real graph.

00:27:34.835 --> 00:27:39.335
Then I'm going to generate a lot of random graphs, um,

00:27:39.335 --> 00:27:44.030
that kind of match the real graph in terms of some statistics like the number of nodes,

00:27:44.030 --> 00:27:45.500
number of edges, uh,

00:27:45.500 --> 00:27:47.000
as well as degree sequence.

00:27:47.000 --> 00:27:50.660
And I'm going to count the frequency of the same motif in this,

00:27:50.660 --> 00:27:53.405
um, um, uh, random graph as well.

00:27:53.405 --> 00:27:57.830
And then I'm going to define next a statistical measure that will

00:27:57.830 --> 00:28:02.690
tell me kind of how- how- how big is the discrepancy between the,

00:28:02.690 --> 00:28:07.775
um, frequency of the motif in the real g raph versus in the random version of it.

00:28:07.775 --> 00:28:12.155
And in the statistic I'm going to define to quantify these is called a Z-score.

00:28:12.155 --> 00:28:15.920
So let me explain, uh, what the Z-score is.

00:28:15.920 --> 00:28:20.750
So, z- score,um, uh, of a given sub-graph

00:28:20.750 --> 00:28:25.115
or a given motif I is- captures its statistically significance.

00:28:25.115 --> 00:28:27.770
And the way we are going to do this is simply say, uh,

00:28:27.770 --> 00:28:32.555
what is the number of times this motif I appears in the real graph?

00:28:32.555 --> 00:28:35.660
What is the average number of times this same

00:28:35.660 --> 00:28:39.020
motif I appears in the random versions of the real graph?

00:28:39.020 --> 00:28:41.420
So because we have multiple instantiations,

00:28:41.420 --> 00:28:43.355
I can compute the average and of course,

00:28:43.355 --> 00:28:45.410
I can also compute the, uh,

00:28:45.410 --> 00:28:48.070
ra-standard deviation of the frequency of

00:28:48.070 --> 00:28:51.955
that motif in these different random instantiations of the,

00:28:51.955 --> 00:28:55.365
uh, random graph corresponding to the, uh, real graph.

00:28:55.365 --> 00:28:57.155
And the Z-score now,

00:28:57.155 --> 00:28:59.915
will basically tell me how much over-

00:28:59.915 --> 00:29:03.575
represented or under-represented is the motif, right?

00:29:03.575 --> 00:29:05.690
And we are, uh, doing two things.

00:29:05.690 --> 00:29:07.880
We compute-we compute, compare

00:29:07.880 --> 00:29:11.585
the frequency in the real graph versus in the random graph.

00:29:11.585 --> 00:29:13.820
But then we also, um,

00:29:13.820 --> 00:29:16.010
divide by the standard deviation,

00:29:16.010 --> 00:29:18.170
by the variance of that, uh,

00:29:18.170 --> 00:29:21.980
of that count across multiple instantiations of the random graph, right?

00:29:21.980 --> 00:29:24.350
So basically, what does this mean is that we somehow

00:29:24.350 --> 00:29:27.740
normalize the count based on the natural variability,

00:29:27.740 --> 00:29:30.740
uh, of- of the- of the count of that motif.

00:29:30.740 --> 00:29:34.270
So now this gives me the Z-score of a given motif I.

00:29:34.270 --> 00:29:38.995
And then what people compute and define is called network significance profile,

00:29:38.995 --> 00:29:41.185
where basically we- we do it such that

00:29:41.185 --> 00:29:45.970
the-the-the sum of the squares of the Z-scores, uh, equals to one.

00:29:45.970 --> 00:29:48.130
So basically we normalize, um,

00:29:48.130 --> 00:29:53.410
the significance profile where at the ith- ith component of the significance profile,

00:29:53.410 --> 00:29:55.435
we take the Z-score of- of, uh,

00:29:55.435 --> 00:30:00.665
sub-graph i and divide it by the square root of the sum of squares,

00:30:00.665 --> 00:30:02.795
uh, of the, uh, Z-scores.

00:30:02.795 --> 00:30:04.895
Uh, notice that Z-score, uh,

00:30:04.895 --> 00:30:07.280
Z-score is such that if it is 0,

00:30:07.280 --> 00:30:08.405
this means that, uh,

00:30:08.405 --> 00:30:12.695
the motif occurs as often in the real graph as in the random graph.

00:30:12.695 --> 00:30:18.500
And then, um, if you know the Z-score is bigger than plus or- or, uh, minus 2,

00:30:18.500 --> 00:30:21.770
then we would say that a given motif is statistically significant,

00:30:21.770 --> 00:30:26.630
appears statistically significantly more often or less often,

00:30:26.630 --> 00:30:29.210
than, uh, what we- what happens,

00:30:29.210 --> 00:30:31.235
uh, in the random graph?

00:30:31.235 --> 00:30:34.445
So, um, and this allows us now to compare

00:30:34.445 --> 00:30:38.360
networks of different sizes because the row counts can be quite different,

00:30:38.360 --> 00:30:39.935
but the Z-scores are,

00:30:39.935 --> 00:30:42.320
uh, size, uh, invariant.

00:30:42.320 --> 00:30:47.420
So significant- significance profile is that basically for every sub-graph,

00:30:47.420 --> 00:30:50.840
we have to count how often it appears in the real graph,

00:30:50.840 --> 00:30:53.015
how often it appears in the random graph.

00:30:53.015 --> 00:30:55.955
We need to do this over multiple random instantiations

00:30:55.955 --> 00:30:58.835
so that we can then compute, uh, the Z-score.

00:30:58.835 --> 00:31:01.640
And we need to do this for every possible sub-graph,

00:31:01.640 --> 00:31:04.265
uh, of a given, uh, size.

00:31:04.265 --> 00:31:06.005
And then for example,

00:31:06.005 --> 00:31:07.835
we can take different networks,

00:31:07.835 --> 00:31:09.890
like gene regulatory network,

00:31:09.890 --> 00:31:13.505
neural networks of synaptic connections between neurons.

00:31:13.505 --> 00:31:15.470
We can take the network of the world wide web,

00:31:15.470 --> 00:31:17.510
we can take a social network, um,

00:31:17.510 --> 00:31:20.450
or even like a network def- defined based on text,

00:31:20.450 --> 00:31:23.090
based on word adjacency and compare, uh,

00:31:23.090 --> 00:31:27.905
frequencies and significant prof- significance profiles, uh, between them.

00:31:27.905 --> 00:31:30.290
And what is interesting, for example,

00:31:30.290 --> 00:31:32.450
here is, these are the 13,

00:31:32.450 --> 00:31:34.805
uh, sub-graphs of size,

00:31:34.805 --> 00:31:37.355
uh, size 3 for directed graphs.

00:31:37.355 --> 00:31:38.615
So these are now, uh,

00:31:38.615 --> 00:31:42.005
my motifs and the y-axis here, is the Z-score.

00:31:42.005 --> 00:31:47.180
And here are different instances of the same type of a- of a network.

00:31:47.180 --> 00:31:49.670
For example, here are three instances of, uh,

00:31:49.670 --> 00:31:52.835
uh, web graphs and three instances of social networks.

00:31:52.835 --> 00:31:56.915
And you can see how basically they have the same significance profile.

00:31:56.915 --> 00:32:00.365
You see, for example, how this triangle of,

00:32:00.365 --> 00:32:04.010
uh, um, mutual connections is heavily overrepresented.

00:32:04.010 --> 00:32:07.265
You notice how this particular motif, for example, here,

00:32:07.265 --> 00:32:10.520
is very, um, is very much under-represented.

00:32:10.520 --> 00:32:12.470
And for example, in social networks,

00:32:12.470 --> 00:32:14.570
this makes sense because this says, you know,

00:32:14.570 --> 00:32:16.985
imagine this is, uh, yourself or myself.

00:32:16.985 --> 00:32:20.885
This means I have two friends to whom I have very strong relationship,

00:32:20.885 --> 00:32:23.270
but these two friends are not friends with each other.

00:32:23.270 --> 00:32:27.185
And actually, social science theory says that what would happen in this case is

00:32:27.185 --> 00:32:32.840
either these two people become friends with each other and you end up with this motif 13,

00:32:32.840 --> 00:32:37.280
or one of these edges will break because simply it is too- too hard

00:32:37.280 --> 00:32:42.080
for you to maintain two separate relationships with two separate persons,

00:32:42.080 --> 00:32:44.240
um, rather than, you know, bringing them together.

00:32:44.240 --> 00:32:47.240
It's almost like saying you have to go to two coffees every

00:32:47.240 --> 00:32:50.900
week versus all three of you going for a coffee and having good time, right?

00:32:50.900 --> 00:32:53.015
Like this is much more hard,

00:32:53.015 --> 00:32:55.205
uh, to maintain, uh, in practice.

00:32:55.205 --> 00:32:57.215
And you see that in, um,

00:32:57.215 --> 00:33:00.980
social networks, this motif is heavily underrepresented.

00:33:00.980 --> 00:33:02.660
Um, but for example,

00:33:02.660 --> 00:33:05.510
you can see that in other types of networks like signaling,

00:33:05.510 --> 00:33:10.640
it's actually the feed-forward type loops here that are, uh, over-represented.

00:33:10.640 --> 00:33:14.120
So basically you can get inside into the, um, uh,

00:33:14.120 --> 00:33:17.450
function of networks by looking at this,

00:33:17.450 --> 00:33:19.700
uh, motif, uh, profile.

00:33:19.700 --> 00:33:22.325
So let me summarize.

00:33:22.325 --> 00:33:25.385
Why did we decide is how do you detect network motifs?

00:33:25.385 --> 00:33:27.650
You, uh, first count sub-graphs,

00:33:27.650 --> 00:33:29.525
I in the real network.

00:33:29.525 --> 00:33:35.465
Then you count the same sub-graph I in the random version of the real network here,

00:33:35.465 --> 00:33:37.295
denoted as G_rand.

00:33:37.295 --> 00:33:41.120
Uh, G_rand is a null model that has the same number of nodes,

00:33:41.120 --> 00:33:42.290
same number of edges,

00:33:42.290 --> 00:33:46.985
and the same degree distribution or the same degree sequence as the real network.

00:33:46.985 --> 00:33:52.370
And then you assign or compute a Z-score for every subgraph i, where you simply say,

00:33:52.370 --> 00:33:56.990
how often did this- this subgraph appear in the real graph minus how

00:33:56.990 --> 00:33:59.225
often does it tend to occur in a random graph

00:33:59.225 --> 00:34:02.150
divided by the standard deviation of the count,

00:34:02.150 --> 00:34:04.550
um, of it in the random graph and,

00:34:04.550 --> 00:34:07.250
uh, you know, motifs with high absolute z- scores.

00:34:07.250 --> 00:34:09.724
This means they are either heavily over- represented

00:34:09.724 --> 00:34:12.440
or heavily under-represented in my graph.

00:34:12.440 --> 00:34:16.490
And that's why we say that they are, uh, significant.

00:34:16.490 --> 00:34:19.040
So, um, and, you know,

00:34:19.040 --> 00:34:21.440
the last thing to say in this case is there are

00:34:21.440 --> 00:34:24.575
many variations of this notion of a motif concept.

00:34:24.575 --> 00:34:28.475
You know, there are extensions to directed and undirected graphs.

00:34:28.475 --> 00:34:30.980
There are extinctions to colored, uh,

00:34:30.980 --> 00:34:33.590
nodes, so meaning nodes with different types.

00:34:33.590 --> 00:34:36.260
There is also extensions to, uh,

00:34:36.260 --> 00:34:39.350
temporal, uh, temporal graphs as well.

00:34:39.350 --> 00:34:41.195
So in temporal motifs.

00:34:41.195 --> 00:34:45.650
Um, and then there is also a lot of variations in terms of how do define frequency?

00:34:45.650 --> 00:34:48.320
How do you define statistical significance?

00:34:48.320 --> 00:34:50.780
How do you define under-representation?

00:34:50.780 --> 00:34:53.780
And can you kind of count anti motifs as well.

00:34:53.780 --> 00:34:56.150
So basically, absence of an edge is important.

00:34:56.150 --> 00:34:59.060
And also, uh, how do you do different null models?

00:34:59.060 --> 00:35:01.790
So there is a huge and very rich literature and

00:35:01.790 --> 00:35:06.065
very active research area in this notion of, uh, motifs.

00:35:06.065 --> 00:35:11.210
So to summarize, motifs and sub-graphs are building blocks of networks.

00:35:11.210 --> 00:35:16.385
Sub-graph isomorphism and sub-graph counting are NP-hard problems.

00:35:16.385 --> 00:35:19.280
Understanding which motifs are frequent or uh,

00:35:19.280 --> 00:35:24.740
significant in a dataset gives us insights into the unique characteristics of the domain.

00:35:24.740 --> 00:35:26.600
And we use random graph, uh,

00:35:26.600 --> 00:35:30.320
null-models as basically as reference points to evaluate

00:35:30.320 --> 00:35:35.490
significance of a given motif by computing, uh, the Z-score.

