Applications of graph machine learning research and its impact across many different applications. 

In graph machine learning, we can formulate different types of tasks. 
- We can formulate tasks at the level of individual nodes. 
- We can formulate tasks at the level of edges which is pairs of nodes. 
- We can identify or define tasks at the level of subgraphs of nodes, 
- as well as the tasks at the level of the entire graphs like for a graph label prediction or graph generation. 

- For node level tasks, we generally talk about node classification, where we are trying to predict a property of a node. For example, categorize online users or categorize items. 
- In link prediction, we try to predict whether there are missing links between a pair of nodes. One such example of this task is knowledge graph completion. 
- In graph level task like graph classification, we try to categorize different graphs. For example, we may want to represent molecules as graphs and then predict properties of molecules. This is especially interesting and important task for drug design where we try to predict properties of different molecules, different drugs. 
- We can also perform clustering or community detection, where the goal is to identify closely knit subparts of the graph where nodes are densely connected or highly connected with each other. Application of these could be social circle detection.
- Graph generation or graph evolution, where graph generation could be, for example, used for drug discovery to generate novel molecular structures. Predicting graph evolution is very useful in physics where we want to run accurate simulations of various kinds of physics phenomena, and that can be represented as a graph. 

So in all these machine learning tasks we use graphs which leads to high impact applications. 
Examples of node level machine learning applications: 
Protein folding
Proteins regulate various biological processes, and, the way that drugs work is to bind or change behavior of different proteins which then then changes the biological processes in our body, and this way we get cured or we we heal. Proteins are composed of amino acids. And we can think of our protein as a sequence of amino acids. However, due magnetic and different kinds of forces, these proteins are not these chains or strains, but they actually fold in very complex shapes. And one of the very important problems in biology, a problem that hasn't yet been solved is given a sequence of amino acids, can you predict the 3D structure of the underlying protein? So the computational task that scientists have been running competitions about since '70s is about how do we computationally predict protein's 3D structure based solely on its amino acid sequence. 
So the question is, given a sequence of amino acids, can we predict the three-dimensional structure of the protein? In the middle of December of 2020 DeepMind announced AlphaFold that increased the performance or the accuracy of this protein folding applications by 30 percent all the way up to the values that are in high 90s. 
And here I just show a couple of  titles of articles in media about how an important achievement this has been, how it changed the biology forever, how it solved one of the largest scientific open problems, and how this will turbocharge drug discovery and all kinds of important implications that this has. 

And what is interesting in this scientific AI machine learning breakthrough is that the key idea that made this possible was to represent the underlying protein as a graph. They represented it as a spatial graph, where nodes in this graph were amino acids in the protein sequence, and the edges corresponded to to amino acids that are spatially close to each other. So this means that now given the positions of all the amino acids and the edges proximities between them, the graph neural network approach was trained that it predicted the new positions of the amino acids. And this way the folding of the protein was able to be simulated and the final positions of the molecules were able to be predicted. So the key ingredient in making this work, in making this scientific breakthrough in protein folding was the use of graph representation and the graph neural network technology. Now this was on the level of nodes, where basically for every node in the graph, we tried to predict its  position in space, and this way tell what is the three-dimensional organization of a protein. 


Edge-level machine learning task, where we are basically doing link prediction or trying to understand relationship between different nodes. 
The first example of this is in recommender systems, where basically we can think of these as users interacting with items, items being products, movies songs, and so on. And we'll have two types of nodes. We will have users, and we would have items. And there is an edge between a user and an item if a user consumed, bought, reviewed a given item or listened to a given song or watched a given movie. And based on the structure of this graph and the properties of the users and the items, we would like to predict or recommend what other items given users might be interested in in the future. 

So we naturally have a bipartite graph and a graph problem. And the modern recommender systems used in companies like Pinterest, LinkedIn Facebook Instagram Alibaba and elsewhere are all based on these graphical representations and use graph representation learning and graph neural networks to make predictions. And the key insight here is that we can basically learn how to embed or how to represent nodes of this graph such that related nodes are embedded closer to each other than nodes that are not related. 

And for example, in case of Pinterest, we can think of Pinterest images as nodes in the graph, and the goal is to embed nodes that are related- images that are related closer together than images that are not related. For example, this sweater and the cake. And the way one can do this is to create this type of bipartite network, where we have the images on the top, and we can have, for example, users or Pinterest boards at the bottom. And then we can define a neural network approach that will take the feature information or attribute information of these different pins, so basically the content of the image, and transform it across the underlying graph to come up with a robust embedding of a given image. And it turns out that this approach works much, much better than if you would just consider images by themselves. So images plus the graph structure leads to much better recommendations than the image themselves. So here in this example of the task, it is about understanding relationships between pairs of nodes or pairs of images by basically saying that nodes that are related should be embedded closer together, the distance between them should be smaller than the distance between pairs of images that are not related to each other. 

Another example of a link level prediction task is very different. This is about drug combination side effects. 
The problem here is that many patients take multiple drugs simultaneously to treat complex and coexisting diseases. For example, in the United States, basically, 50 percent of people over 70 years of age simultaneously take four or five or more drugs. And there are many patients who take 20 plus drugs to treat many complex coexisting diseases. For example, somebody who suffers insomnia, suffers depression, and has a heart disease, all simultaneously will take many different drugs altogether at once. And the problem is that these drugs interact with each other and they lead to new adverse side effects. So basically, the interactions between drugs leads to additional diseases  or additional problems in that human. and of course, the number of combinations of different drugs is too big, so we cannot experimentally or in clinical trials test every combination of drugs to see what kind of side effects does it lead to. So the question is, can we build up predictive engine that for an arbitrary pair of drugs will predict how these drugs are going to interact, and what kind of adverse side effects they may cause? And this is also a graph problem. So let me tell you how we formulate it. we create this two-level heterogeneous network where triangles are the different drugs and circles are proteins in our bodies. And then the way drugs work is that they target the different proteins. So these are the edges between triangles and the circles. And biologists have been mapping out the protein-protein interaction network where they experimentally test whether two proteins physically come together and interact to regulate a given biological process or function. So we also know, experimentally, which proteins interact with each other. And this is called a protein-protein interaction network, or also called the interactome. And then the last set of links we have in this graph are the known side-effects where basically, for example, the link between the node C and node M says that if you take these two drus- drugs together, the side-effect of type R is known to occur. Of course, this network up here of side-effects is notoriously incomplete and has a lot of missing connections. So the question becomes, can we impute, can we predict the missing edges, missing connections in this network that would basically tell, us what kind of side-effects can we expect if we take or if a person takes two drugs simultaneously? So the way we think of this, we think of it as a link prediction between triangular nodes of the graph, where basically the question is, given the two drugs, what kind of side effects may occur? And what is interesting is that you can apply this method very accurately and you can discover new side effects that haven't been known in the past. For example, in this in this case the model outputted the top ten predictions it is most certain about, where basically the way you read it is to say if you think these two drugs, then this particular side effect is likely to occur. And none of these side-effects are actually in the official FDA database. So what the authors did here is they took the top 10 predictions from the model and then they looked in the medical literature and clinical medical notes to see if there are any reports that could tell us whether and provide evidence of whether this particular pair of drugs could lead to a given side-effect. Then actually, for the five out of top 10, we actually found that there is some research evidence that points that this that this predictions might actually be true. So these were the machine learning tasks at the level of pairs of nodes. 

The sub-graph level machine learning task. 
Here is one very recent that we are all using every day. It's about traffic prediction. So for example, if today you open Google Maps and you say I wanna drive from Stanford all the way up to Berkeley Google will tell you how long it will take you to get there and what is your estimated time of arrival. And I'm not sure you knew, but actually in the end, graph machine learning is used to make these predictions of the travel time, and the way the graph is created is that nodes represent a road segments and connectivity between road segments is captured by the edges of this network. And then our graph neural network approach is trained that based on the conditions and traffic patterns on each of the road segment as well as the path between the source and the destination  of the journey the graph neural network approach is trained to predict the estimate that time of arrival or travel time. And it has been announced that actually this graph-based approach is used in production in Google Maps, so whenever you are asking for directions, there is actually a graph machine learning-based approach that tells you when are you going to arrive to a given location. 

Interesting impactful applications of graph-level tasks. 
One very recent is around drug discovery. And actually, graph-based machine learning was used to discover new drugs, new antibiotics. Antibiotics are small molecular graphs and we can represent molecules as graphs where the nodes are atoms and edges correspond to chemical bonds. So each molecule can be represented as a graph. But then we have these banks or collections of billions of molecules. And the question is, which molecules could have therapeutic effect. So essentially, which molecules should be prioritized so that biologists can pass them in the laboratory to validate or their therapeutic effect. And actually, a team at MIT was using graph based deep learning approach for antibiotic discovery where they used a graph neural network to classify different molecules and predict promising molecules from a pool of billions of candidates. And then these predictions would have further validated in the lab. And there is a very exciting breakthrough paper published in journal cell just this year about how these graph-based approach allows us to efficiently and quickly discover new drugs and new therapeutic uses of different types of molecules. To further talk about drug discovery we can think also about graph generation as a way to discover new molecules that have never been synthesized or considered before. And this is very useful because it allows us to generate new structures, new molecules in various kinds of targeted ways. For example, we can say generate new molecules that are non-toxic, generate new molecules that have high solubility, generate new molecules that have high drug likeness. So we can generate now molecules as graphs in a targeted way. 

Not even that. The second use case is that we can optimize existing molecules to have a desirable property. So basically, the use case here is that you have a small part of the molecule that has a given therapeutic effect, for example. And now we wanna complete the rest of the molecule scaffold so that you improve a given property. For example solubility and this type of deep graph generative models can be used for tasks like molecule generation and optimization. 

Realistic physics-based simulation. 
In this case, we can basically have different materials. We represent the material as a set of particles and then we can have a graph defined on top of these set of particles that capture which particles interact with each other. And now the underlying task for the machine learning is to say, predict how this graph is going to evolve in the future. And this allows us to predict how this material is going to deform. so let me tell you how this is done. The way this is done is that essentially we iterate the following approach. We take the material and we represent it as a set of particles. Based on the proximities, interactions between the particles, we generated the proximity graph. Now, that we have this proximity graph, we apply graph machine learning, a graph neural network, that takes the current properties, meaning positions, as well as velocities of the particles and predict what will be the positions and velocities of the particles in the future. And now based on this prediction, we can move, evolve the particles to their new positions, and then again, we go to the first step where now based on this new proximities, we create the new graph, predict the new positions move the particles and keep iterating this. And this allows for very fast and very accurate physics-based simulations. So these were some examples of graph of a graph-level tasks and important applications of graph machine learning to various domains across across sciences, industry, as well as different consumer products. 